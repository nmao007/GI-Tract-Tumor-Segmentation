# Abstract
Stomach cancer is a widespread problem and is the fifth most common cancer worldwide.  Many cases of stomach cancer require radiation treatment, which has doctors target high-energy radiation onto the cancer cells.  This means that before they perform the treatment, the doctors need to outline exactly where the tumor is to minimize the radiation that hits the organs around it.  Previously, studies have been conducted using various deep learning models like the Mask R-CNN model or the U-net.  At Stanford, a group of researchers concluded that the Mask R-CNN was a more effective model than the U-net.  For this study, I aim to confirm whether the U-net is a viable option for this tumor segmentation task or not and see if it is possible to tweak the U-net’s parameters to procure a better result.  I used data from Kaggle’s UW Madison GI Tract segmentation competition, which provides both images and masks.  After loading and sizing the images to 256x256, I applied some data augmentation, generating more images by rotating and stretching previous ones.  Then, after constructing each layer of the U-net and testing on validation data, I found the validation accuracy to be 96.05% and the validation loss to be 0.1632, calculated by binary crossentropy.  However, my model was behaving strangely, sometimes having a recall of 1.0 and 0.0, so our final metrics most likely are not reliable.  There is still research to be done about U-nets, but they do seem to be very effective in segmentation tasks like these.

# Introduction
Stomach cancer is one of the most detrimental problems ever, ranking as the 5th most common cancer worldwide and racking up over a million diagnoses and about 700 thousand deaths each year.  Of these patients, many are eligible for radiation treatment, which is one of the preferred ways to deal with these tumors.  The problem, however, is that sometimes these beams of radiation are not accurate, and can end up damaging the surrounding vital organs.
 
But today, in a world brimming with new powerful technological advancements with AI leading the pack, humanity might just have the power to change that.  This study will harness the current tools provided by the AI revolution — namely, Convolutional Neural Networks and Unets — to aid doctors working in the Stomach Cancer field to make their procedures more efficient and hassle free, automating the tumor segmentation aspect of the process.  There have been many previous works in this area, mostly stemming from Kaggle’s UW Madison GI Tract segmentation competition.  A study conducted at Stanford concluded that the Mask R CNN was better than the U-net for this segmentation job, and they hypothesized that it was because the U-net’s loss function was “formulated in too naive a way compared to the Mask R-CNN model.”  However, an overwhelming majority of the other studies done on Kaggle preferred the U-net over any other model.
 
For this study, there are quite a few prerequisites that we need to know about.  The most fundamental aspect to understand is the concept of images and masks.  For segmentation, we are usually given an image and the task of separating the image into two parts.  The mask is a black and white image that depicts the correct separation — white represents the segmented part, black represents the background.  Now, once we have the images and masks, we need to understand the preprocessing part of this procedure, which mainly consists of image augmentation and normalization.  Image augmentation is the process of using the given images to create synthetic images, usually made from a series of flips, zooms, or twists of the previous image, and normalization is the process of scaling the pixel values to a certain range, usually from 0 to 1.  For this study, we are using png images.  The last thing we need to do is understand how our model works.  The U-net is a modified Convolutional Neural Network (CNN) that concatenates previous layers to the current layer, giving it the “U” shape.   
 
In this study, as mentioned before, we first preprocess images using augmentation and normilization.  Then, we need to construct our preferred model.  This time, we have selected a U-net because of its proficiency with image segmentation tasks.  Following the construction, all that is left to do is train our model.  Through our construction of the U-net, we aim to gain a deeper understanding about how deep learning can aid stomach cancer research, the advantages and disadvantages of medical automation, and possibly even provide a useful tool available to doctors anywhere in the world.

# Procedure
After clarifying and understanding our data, we now need to embark on one of our most important steps, which is image preprocessing.  Image preprocessing, generally, is the process of preparing data for training.  Our preprocessing procedure consisted of loading the image, resizing the image, producing synthetic data, and finally normalizing all the images.  As defined before, producing synthetic data is called augmentation, and it is the process of flipping, rotating, or stretching our given image mask pair to create new images and masks.  Normalization, also mentioned before, is the process of scaling the pixel values of 0 to 255 into the range of 0 to 1, keeping the pixel values consistent over every image.  Finally, when we load and resize the image, all we are doing is extracting the image from our dataset and resizing it from 256 x 256 to 128 x 128.  We do this because making the images smaller does not decrease its resolution significantly, but it does decrease the necessary memory significantly.  Putting all of these functions into one general function, we can simplify the preprocessing procedure to just one function, making the code more readable and simple.
 
Now, finally, after we finish preprocessing, we decide which model to use.  For this study, we have opted for the U-net because of its extensive history dealing with image segmentation tasks just like these.  But why is the U-net so efficient for these segmentation tasks?  It is because of the special architecture of the U-net.  See the U-net architecture image again, and you will notice the arrows between the encoder path (path going down on the left) and the decoder path (path going up on the right).  This is called concatenation, and it is what gives the U-net its U shape.  Its effect on the U-net is exactly why the U-net is so proficient with image segmentation;  it allows the U-net to factor in both coarse images (the image from the encoder path) and fine images (the image from the decoder path), letting it produce more accurate segmentations.  After deciding on the U-net model, we now have to actually build it.  There are a few variations to how we can choose to do this, the main option being what Activation we use and what other functions we use in our convolution layer.  Activation is a variable that allows the model to learn more complicated patterns, rather than just simple linear ones.  For this study, I used the Activation “ReLu”, which is recommended for segmentation tasks. Relu, or any variant of Relu, is preferred because it is simple and easy to use.  For more information on the U-net, its benefits, and its construction, refer to https://arxiv.org/abs/1505.04597.
